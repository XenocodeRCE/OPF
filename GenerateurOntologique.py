import os
import json
import requests
from tqdm import tqdm
import time
import openai
import sys

try:
    from colorama import Fore, Style, init as colorama_init
    colorama_init()
    COLOR = True
except ImportError:
    COLOR = False

def cprint(text, color=None, bold=False, end="\n"):
    if COLOR:
        c = getattr(Fore, color.upper(), "") if color else ""
        b = Style.BRIGHT if bold else ""
        print(f"{b}{c}{text}{Style.RESET_ALL}", end=end)
    else:
        print(text, end=end)

# ---------- CONFIGURATION ----------
OPENAI_API_KEY = ""  # Mets ta cl√© directe ici
openai.api_key = OPENAI_API_KEY

API_URL = "https://philo-lycee.fr/api/dictionnaire.php?id="
OUTFILE = "concepts_ontologie.json"

types_relations = [
    "IMPLIQUE", "CONTREDIT", "EST_EQUIVALENT", "EST_UN", "FAIT_PARTIE_DE",
    "A_COMME_PROPRIETE", "CAUSE", "PERMET", "EMPECHE", "DEFINIT", "EXPLIQUE",
    "ATTESTE", "PRECEDE", "SUIT", "S_OPPOSE_A", "COMPLEMENTE", "SUBSUME",
    "EST_ANALOGUE_A", "DEPEND_DE", "EST_COMPOSE_DE", "NECESSITE", "POSSIBLE_SI",
    "INSTANCE_DE", "CONSTITUE", "VISE", "MEMBRE_DE", "IDENTIQUE_A", "PERSONNALISEE"
]

# ---------- EXPLICATIONS DES RELATIONS ----------
relation_explications = {
    "implique": "Relation d'implication logique ou conceptuelle‚ÄØ: ce concept entra√Æne n√©cessairement ou logiquement un autre.",
    "contredit": "Relation de contradiction‚ÄØ: ce concept est incompatible ou s'oppose logiquement √† un autre.",
    "est_equivalent": "Relation d'√©quivalence‚ÄØ: ce concept a la m√™me signification ou valeur qu'un autre.",
    "est_un": "Relation d'appartenance √† une cat√©gorie (is_a)‚ÄØ: ce concept est un exemple ou un cas particulier d'une cat√©gorie plus g√©n√©rale.",
    "fait_partie_de": "Relation de m√©ronomie (part_of)‚ÄØ: ce concept est une partie constituante d'un tout.",
    "a_comme_propriete": "Relation attributive‚ÄØ: ce concept poss√®de une propri√©t√© ou caract√©ristique particuli√®re.",
    "cause": "Relation causale‚ÄØ: ce concept produit ou engendre un autre concept.",
    "permet": "Relation d'activation ou de permission‚ÄØ: ce concept rend possible ou facilite un autre concept.",
    "empeche": "Relation d'emp√™chement ou d'inhibition‚ÄØ: ce concept rend impossible ou bloque un autre concept.",
    "definit": "Relation de d√©finition‚ÄØ: ce concept sert √† d√©finir ou √† pr√©ciser un autre concept.",
    "explique": "Relation d'explication‚ÄØ: ce concept √©claire ou justifie un autre concept.",
    "atteste": "Relation d'√©vidence ou de preuve‚ÄØ: ce concept sert de preuve ou d'indication pour un autre concept.",
    "precede": "Relation temporelle ou logique de pr√©c√©dence‚ÄØ: ce concept vient avant un autre dans le temps ou la logique.",
    "suit": "Relation temporelle ou logique de succession‚ÄØ: ce concept vient apr√®s un autre dans le temps ou la logique.",
    "s_oppose_a": "Relation d'opposition ou d'antagonisme‚ÄØ: ce concept est en tension ou en conflit avec un autre.",
    "complemente": "Relation de compl√©mentarit√©‚ÄØ: ce concept compl√®te ou s'associe harmonieusement √† un autre concept.",
    "subsume": "Relation de subsomption‚ÄØ: ce concept englobe, contient ou subsume une cat√©gorie de concepts plus sp√©cifiques.",
    "est_analogue_a": "Relation d'analogie ou de similarit√©‚ÄØ: ce concept pr√©sente des ressemblances ou une structure comparable √† un autre.",
    "depend_de": "Relation de d√©pendance‚ÄØ: ce concept n'existe ou ne fonctionne qu'en relation avec un autre.",
    "est_compose_de": "Relation de composition‚ÄØ: ce concept est constitu√© de plusieurs √©l√©ments ou parties.",
    "necessite": "Relation de n√©cessit√©‚ÄØ: ce concept requiert absolument un autre pour exister ou fonctionner.",
    "possible_si": "Relation de possibilit√© conditionnelle‚ÄØ: ce concept n'est r√©alisable que si un autre est pr√©sent ou r√©alis√©.",
    "instance_de": "Relation d'instanciation‚ÄØ: ce concept est un cas particulier ou un exemple concret d'une cat√©gorie.",
    "constitue": "Relation de constitution‚ÄØ: ce concept forme la base ou la substance d'un autre concept.",
    "vise": "Relation de finalit√©, de but (t√©l√©ologie)‚ÄØ: ce concept tend vers un objectif ou une fin.",
    "membre_de": "Relation d'appartenance √† un ensemble/groupe‚ÄØ: ce concept appartient √† un groupe ou une collection.",
    "identique_a": "Relation d'identit√©‚ÄØ: ce concept est exactement le m√™me qu'un autre.",
    "personnalisee": "Pour toute relation sp√©cifique non pr√©vue dans la liste des relations standards.",
}

# ---------- PARAM√àTRES DE CO√õT OPENAI ----------
COST_PER_1M_INPUT = 1.10  # $/1M tokens input
COST_PER_1M_OUTPUT = 4.40  # $/1M tokens output
AVG_INPUT_TOKENS = 300  # estimation grossi√®re par requ√™te
AVG_OUTPUT_TOKENS = 50  # estimation grossi√®re par requ√™te

def estimate_cost_per_request():
    input_cost = (AVG_INPUT_TOKENS / 1_000_000) * COST_PER_1M_INPUT
    output_cost = (AVG_OUTPUT_TOKENS / 1_000_000) * COST_PER_1M_OUTPUT
    return input_cost + output_cost

def format_time(seconds):
    if seconds < 60:
        return f"{int(seconds)}s"
    elif seconds < 3600:
        m, s = divmod(int(seconds), 60)
        return f"{m}m{s:02d}s"
    else:
        h, rem = divmod(int(seconds), 3600)
        m, s = divmod(rem, 60)
        return f"{h}h{m:02d}m{s:02d}s"

def format_cost(cost):
    return f"{cost:.4f} $"

# ---------- FONCTIONS UTILES ----------
def get_mot_def(id):
    """R√©cup√®re le mot et la d√©finition pour un id donn√©."""
    cprint(f"‚è≥ R√©cup√©ration du mot et de la d√©finition pour l'id {id}...", "cyan")
    try:
        r = requests.get(API_URL + str(id))
        data = r.json()
        if data.get('success'):
            cprint(f"‚úÖ Mot trouv√© : {data['mot']}", "green")
            return data['mot'], data['defmot']
        else:
            cprint(f"‚ùå Aucun mot trouv√© pour l'id {id}.", "red")
            return None, None
    except Exception as e:
        cprint(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration de l'id {id} : {e}", "red")
        return None, None

def openai_concepts(mot, definition, relation, explication):
    """Demande √† OpenAI des concepts reli√©s via une relation donn√©e, explication incluse."""
    cprint(f"üß† Appel OpenAI pour '{mot}' - relation '{relation}'...", "magenta")
    system = (
        "Tu es un expert en philosophie. Pour chaque relation conceptuelle propos√©e, "
        "donne entre 5 et 10 concepts fran√ßais UNIQUEMENT EN MAJUSCULES, s√©par√©s par des virgules, "
        "qui sont li√©s au mot selon la relation, sans explication. Un concept = 1 mot."
    )
    prompt = (
        f"Mot : {mot}\n"
        f"D√©finition : {definition}\n"
        f"Relation : {relation}\n"
        f"Explication de la relation : {explication}\n"
        "Quels concepts sont li√©s √† ce mot par cette relation ?"
    )
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        text = response.choices[0].message.content.strip()
        concepts = [c.strip() for c in text.replace('.', '').split(',') if c.strip()]
        cprint(f"   ‚Üí Concepts trouv√©s : {', '.join(concepts)}", "yellow")
        return concepts
    except Exception as e:
        cprint(f"‚ö†Ô∏è Erreur OpenAI : {e}", "red")
        return []

def ollama_concepts(mot, definition, relation, explication, model="llama3.1:latest"):
    """Demande √† Ollama des concepts reli√©s via une relation donn√©e, explication incluse."""
    cprint(f"üß† (Ollama) Appel pour '{mot}' - relation '{relation}'...", "magenta")
    system = (
        "Tu es un expert en philosophie. Pour chaque relation conceptuelle propos√©e, "
        "donne entre 5 et 10 concepts fran√ßais UNIQUEMENT EN MAJUSCULES, s√©par√©s par des virgules, "
        "qui sont li√©s au mot selon la relation, sans explication. Un concept = 1 mot."
    )
    prompt = (
        f"Mot : {mot}\n"
        f"D√©finition : {definition}\n"
        f"Relation : {relation}\n"
        f"Explication de la relation : {explication}\n"
        "Quels concepts sont li√©s √† ce mot par cette relation ?"
    )
    try:
        response = requests.post(
            "http://localhost:11434/api/chat",
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": system},
                    {"role": "user", "content": prompt}
                ],
                "stream": False
            },
            timeout=120
        )
        response.raise_for_status()
        data = response.json()
        # Ollama renvoie 'message' ou 'messages'
        if "message" in data:
            text = data["message"]["content"].strip()
        elif "messages" in data and data["messages"]:
            text = data["messages"][-1]["content"].strip()
        else:
            text = ""
        concepts = [c.strip() for c in text.replace('.', '').split(',') if c.strip()]
        cprint(f"   ‚Üí Concepts trouv√©s (Ollama) : {', '.join(concepts)}", "yellow")
        return concepts
    except Exception as e:
        cprint(f"‚ö†Ô∏è Erreur Ollama : {e}", "red")
        return []

def load_json(filename):
    if os.path.exists(filename):
        cprint(f"üìÇ Chargement du fichier existant : {filename}", "cyan")
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    cprint(f"üÜï Aucun fichier existant, cr√©ation d'un nouveau dictionnaire.", "cyan")
    return {}

def save_json(data, filename):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    cprint(f"üíæ Sauvegarde dans {filename}", "green")

def print_separator():
    cprint("-" * 60, "blue")

# ---------- GLOBAL OLLAMA FLAG ----------
OLLAMA = True  # Peut √™tre modifi√© manuellement ici (True/False)

# ---------- SCRIPT PRINCIPAL ----------
def main(start_id=471, end_id=6120, use_ollama=False, ollama_model="llama3.1:latest"):
    global OLLAMA
    # Priorit√© √† la valeur manuelle si modifi√©e, sinon celle du CLI
    if OLLAMA is not None:
        use_ollama = OLLAMA
    OLLAMA = use_ollama
    cprint("=== G√©n√©rateur Ontologique Philosophie ===", "blue", bold=True)
    cprint(f"Traitement des IDs de {start_id} √† {end_id}", "blue")
    print_separator()
    data = load_json(OUTFILE)
    total = end_id - start_id + 1
    already = sum(1 for idx in range(start_id, end_id + 1) if str(idx) in data)
    cprint(f"{already}/{total} d√©j√† trait√©s. D√©but du traitement...", "cyan")
    print_separator()

    ids_to_process = [idx for idx in range(start_id, end_id + 1) if str(idx) not in data]
    nb_relations = len(types_relations)
    total_requests = len(ids_to_process) * nb_relations
    cost_per_req = estimate_cost_per_request()
    total_cost_est = total_requests * cost_per_req

    if not use_ollama:
        cprint(f"üí∏ Co√ªt estim√© total pour ce run : {format_cost(total_cost_est)}", "magenta", bold=True)
    else:
        cprint(f"ü¶ô Mode Ollama activ√© (mod√®le : {ollama_model}) ‚Äî Pas de co√ªt estim√©, usage local gratuit.", "green", bold=True)
    print_separator()

    start_time = time.time()
    processed_requests = 0

    for idx_pos, idx in enumerate(tqdm(ids_to_process, desc="Concepts", ncols=100)):
        mot, definition = get_mot_def(idx)
        if not mot:
            cprint(f"‚è© Passage de l'id {idx} (mot non trouv√©).", "red")
            continue

        entry = {
            "mot": mot,
            "definition": definition,
            "relations": {}
        }

        for rel_pos, relation in enumerate(types_relations):
            relation_key = relation.lower().replace("√©", "e").replace("√†", "a").replace("√®", "e").replace("√™", "e").replace("√π", "u").replace("√ª", "u").replace("√ß", "c").replace("'", "_").replace(" ", "_")
            explication = relation_explications.get(relation_key, "")
            cprint(f"üîó [{mot}] Relation : {relation}", "blue")
            if explication:
                cprint(f"   Explication : {explication}", "cyan")
            else:
                cprint("   (Pas d'explication trouv√©e pour cette relation)", "red")

            req_start = time.time()
            if use_ollama:
                concepts = ollama_concepts(mot, definition, relation, explication, model=ollama_model)
            else:
                concepts = openai_concepts(mot, definition, relation, explication)
            req_end = time.time()
            req_duration = req_end - req_start

            entry["relations"][relation] = {
                "explication": explication,
                "concepts": concepts
            }

            processed_requests += 1
            elapsed = time.time() - start_time
            avg_time_per_req = elapsed / processed_requests if processed_requests else 0.0
            remaining_requests = total_requests - processed_requests
            est_time_left = avg_time_per_req * remaining_requests
            est_cost_left = remaining_requests * cost_per_req

            cprint(f"   ‚è±Ô∏è Temps pour cette requ√™te : {format_time(req_duration)}", "cyan")
            if not use_ollama:
                cprint(f"   üí∏ Co√ªt de cette requ√™te : {format_cost(cost_per_req)}", "magenta")
                cprint(f"   ‚è≥ Temps estim√© restant : {format_time(est_time_left)}", "yellow")
                cprint(f"   üí∞ Co√ªt total estim√© restant : {format_cost(est_cost_left)}", "yellow", bold=True)
            else:
                cprint(f"   ‚è≥ Temps estim√© restant : {format_time(est_time_left)}", "yellow")

            cprint("   Pause pour √©viter le rate limit...", "magenta")
            time.sleep(1.3)

        data[str(idx)] = entry
        save_json(data, OUTFILE)
        cprint("   Petite pause avant le prochain mot...", "magenta")
        print_separator()
        time.sleep(1)

        tqdm.write(
            f"üü¶ Progression : {processed_requests}/{total_requests} requ√™tes | "
            f"Temps √©coul√© : {format_time(elapsed)} | "
            f"Temps restant estim√© : {format_time(est_time_left)}"
            + (f" | Co√ªt restant estim√© : {format_cost(est_cost_left)}" if not use_ollama else "")
        )

    cprint("üéâ Traitement termin√© !", "green", bold=True)
    cprint(f"Tous les r√©sultats sont dans {OUTFILE}", "green")
    print_separator()

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="G√©n√©rateur Ontologique Philosophie (CLI)")
    parser.add_argument("--start", type=int, default=471, help="ID de d√©but (d√©faut: 471)")
    parser.add_argument("--end", type=int, default=6120, help="ID de fin (d√©faut: 6120)")
    parser.add_argument("--outfile", type=str, default=OUTFILE, help="Fichier de sortie JSON")
    parser.add_argument("--ollama", action="store_true", help="Utiliser Ollama local (llama3.1:latest)")
    parser.add_argument("--ollama-model", type=str, default="llama3.1:latest", help="Nom du mod√®le Ollama (d√©faut: llama3.1:latest)")
    args = parser.parse_args()

    OUTFILE = args.outfile

    main(
        start_id=args.start,
        end_id=args.end,
        use_ollama=args.ollama,
        ollama_model=args.ollama_model
    )